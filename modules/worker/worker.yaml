#cloud-config
coreos:
  flannel:
    interface: $private_ipv4
    etcd_cafile: /etc/kubernetes/ssl/ca.pem
    etcd_certfile: /etc/kubernetes/ssl/worker.pem
    etcd_keyfile: /etc/kubernetes/ssl/worker-key.pem
    etcd_endpoints: https://${ETCD_IP}:2379

  locksmith:
    endpoint: https://${ETCD_IP}:2379
    etcd_cafile: /etc/kubernetes/ssl/ca.pem
    etcd_certfile: /etc/kubernetes/ssl/worker.pem
    etcd_keyfile: /etc/kubernetes/ssl/worker-key.pem

  update:
    reboot-strategy: etcd-lock

  units:
    - name: flanneld.service
      command: start
      drop-ins:
        - name: 50-network-config.conf
          content: |
            [Unit]
            ConditionFileNotEmpty=/etc/kubernetes/ssl/ca.pem
            ConditionFileNotEmpty=/etc/kubernetes/ssl/worker.pem
            ConditionFileNotEmpty=/etc/kubernetes/ssl/worker-key.pem
            After=prefetch-flannel.service
            Requires=prefetch-flannel.service
            Description=Prefetch flannel
            [Service]
            EnvironmentFile=/etc/environment
            Environment="ETCD_SSL_DIR=/etc/kubernetes/ssl"
            ExecStartPre=-/usr/bin/etcdctl mk /coreos.com/network/config \
              '{ "Network": "${ POD_NETWORK }", "Backend": { "Type": "vxlan" } }'
            Restart=always
            RestartSec=10
    - name: locksmithd.service
      command: start
      drop-ins:
        - name: 01-wait-for-certs.conf
          content: |
            [Unit]
            ConditionFileNotEmpty=/etc/kubernetes/ssl/ca.pem
            ConditionFileNotEmpty=/etc/kubernetes/ssl/worker.pem
            ConditionFileNotEmpty=/etc/kubernetes/ssl/worker-key.pem
    - name: docker.service
      command: start
      drop-ins:
        - name: 40-flannel.conf
          content: |
            [Unit]
            After=flanneld.service
            Requires=flanneld.service
            [Service]
            Restart=always
            RestartSec=10
    - name: prefetch-flannel.service
      command: start
      content: |
        [Unit]
        After=network-online.target
        Requires=network-online.target
        Description=Prefetch flannel
        [Service]
        Type=oneshot
        RemainAfterExit=yes
        ExecStart=/usr/bin/rkt fetch --insecure-options=all ${S3_LOCATION}/flannel_${FLANNEL_VERSION}.aci
    - name: prefetch-docker-hyperkube.service
      command: start
      content: |
        [Unit]
        After=docker.service
        Requires=docker.service
        After=docker-ecr-cfg.service
        Requires=docker-ecr-cfg.service
        Description=Prefetch docker Hyperkube
        [Service]
        Type=oneshot
        RemainAfterExit=yes
        ExecStartPre=/usr/bin/docker pull ${HYPERKUBE_ECR_LOCATION}/hyperkube:${HYPERKUBE_VERSION}
        ExecStart=/usr/bin/docker tag ${HYPERKUBE_ECR_LOCATION}/hyperkube:${HYPERKUBE_VERSION} ${ HYPERKUBE_IMAGE}:${HYPERKUBE_VERSION}
    - name: kubelet.service
      command: start
      content: |
        [Unit]
        ConditionFileIsExecutable=/usr/lib/coreos/kubelet-wrapper
        ConditionFileNotEmpty=/etc/kubernetes/ssl/worker.pem
        ConditionFileNotEmpty=/etc/kubernetes/ssl/worker-key.pem
        After=flanneld.service
        Requires=flanneld.service
        After=prefetch-docker-hyperkube.service
        Requires=prefetch-docker-hyperkube.service
        [Service]
        Environment="KUBELET_IMAGE=${S3_LOCATION}/hyperkube_${HYPERKUBE_VERSION}.aci"
        Environment="RKT_RUN_ARGS=\
          --uuid-file-save=/var/run/kubelet-pod.uuid \
          --insecure-options=image \
          --volume dns,kind=host,source=/etc/resolv.conf \
          --mount volume=dns,target=/etc/resolv.conf \
          --volume var-log,kind=host,source=/var/log \
          --mount volume=var-log,target=/var/log"
        ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/manifests
        ExecStartPre=/usr/bin/mkdir -p /var/log/containers
        ExecStartPre=-/usr/bin/rkt rm --uuid-file=/var/run/kubelet-pod.uuid
        ExecStart=/usr/lib/coreos/kubelet-wrapper \
          --allow-privileged=true \
          --anonymous-auth=false \
          --api-servers=https://${MASTER_HOST} \
          --cloud-provider=aws \
          --client-ca-file=/etc/kubernetes/ssl/ca.pem \
          --cluster-dns=${DNS_SERVICE_IP} \
          --cluster-domain=${CLUSTER_DOMAIN} \
          --cni-conf-dir=/etc/kubernetes/cni/net.d \
          --container-runtime=docker \
          --hostname-override=$private_ipv4 \
          --kubeconfig=/etc/kubernetes/worker-kubeconfig.yaml \
          --node-labels node-role.kubernetes.io/node \
          --pod-infra-container-image=${POD_INFRA_CONTAINER_IMAGE} \
          --pod-manifest-path=/etc/kubernetes/manifests \
          --register-node=true \
          --tls-cert-file=/etc/kubernetes/ssl/worker.pem \
          --tls-private-key-file=/etc/kubernetes/ssl/worker-key.pem
        ExecStop=-/usr/bin/rkt stop --uuid-file=/var/run/kubelet-pod.uuid
        Restart=always
        RestartSec=10
        [Install]
        WantedBy=multi-user.target
    - name: docker-ecr-cfg.service
      command: start
      content: |
        [Unit]
        After=docker.service
        Requires=docker.service
        Description=docker ecr login
        [Service]
        Type=oneshot
        RemainAfterExit=yes
        ExecStartPre=/opt/bin/docker-login-gen
        ExecStart=/opt/bin/docker-login

write_files:
  - path: "/opt/bin/docker-login-gen"
    permissions: 0755
    owner: root:root
    content: |
      #!/bin/bash -e
      echo "#!/bin/bash -e" > /opt/bin/docker-login
      until /usr/bin/docker run \
        --rm daocloud.io/mixslice/awscli \
        aws ecr get-login --region=cn-north-1 >> /opt/bin/docker-login
      do
        echo "retrying"
        sleep 5.2
      done
      chmod +x /opt/bin/docker-login
      echo "âœ“"
  - path: "/etc/environment"
    permissions: 0644
    content: |
      COREOS_PRIVATE_IPV4=$private_ipv4
      ETCD_CA_FILE=/etc/kubernetes/ssl/ca.pem
      ETCD_CERT_FILE=/etc/kubernetes/ssl/client.pem
      ETCD_KEY_FILE=/etc/kubernetes/ssl/client-key.pem
      ETCDCTL_CA_FILE=/etc/kubernetes/ssl/ca.pem
      ETCDCTL_CERT_FILE=/etc/kubernetes/ssl/client.pem
      ETCDCTL_KEY_FILE=/etc/kubernetes/ssl/client-key.pem
      ETCDCTL_ENDPOINT=https://${ETCD_IP}:2379
  - path: "/etc/kubernetes/manifests/kube-proxy.yaml"
    permissions: 0644
    content: |
        apiVersion: v1
        kind: Pod
        metadata:
          name: kube-proxy
          namespace: kube-system
        spec:
          hostNetwork: true
          containers:
          - name: kube-proxy
            image: ${HYPERKUBE_IMAGE}:${HYPERKUBE_VERSION}
            command:
            - /hyperkube
            - proxy
            - --master=https://${MASTER_HOST}
            - --kubeconfig=/etc/kubernetes/proxy-kubeconfig.yaml
            - --proxy-mode=iptables
            securityContext:
              privileged: true
            volumeMounts:
              - mountPath: /etc/ssl/certs
                name: "ssl-certs"
              - mountPath: /etc/kubernetes/proxy-kubeconfig.yaml
                name: "kubeconfig"
                readOnly: true
              - mountPath: /etc/kubernetes/ssl
                name: "etc-kube-ssl"
                readOnly: true
          volumes:
            - name: "ssl-certs"
              hostPath:
                path: "/usr/share/ca-certificates"
            - name: "kubeconfig"
              hostPath:
                path: "/etc/kubernetes/proxy-kubeconfig.yaml"
            - name: "etc-kube-ssl"
              hostPath:
                path: "/etc/kubernetes/ssl"
  - path: "/etc/kubernetes/worker-kubeconfig.yaml"
    permissions: 0644
    content: |
        apiVersion: v1
        kind: Config
        clusters:
        - name: local
          cluster:
            certificate-authority: /etc/kubernetes/ssl/ca.pem
        users:
        - name: kubelet
          user:
            client-certificate: /etc/kubernetes/ssl/worker.pem
            client-key: /etc/kubernetes/ssl/worker-key.pem
        contexts:
        - context:
            cluster: local
            user: kubelet
          name: kubelet-context
        current-context: kubelet-context
  - path: "/etc/kubernetes/proxy-kubeconfig.yaml"
    permissions: 0644
    content: |
        apiVersion: v1
        kind: Config
        clusters:
        - name: local
          cluster:
            certificate-authority: /etc/kubernetes/ssl/ca.pem
        users:
        - name: kubelet
          user:
            client-certificate: /etc/kubernetes/ssl/proxy.pem
            client-key: /etc/kubernetes/ssl/proxy-key.pem
        contexts:
        - context:
            cluster: local
            user: kubelet
          name: kubelet-context
        current-context: kubelet-context
